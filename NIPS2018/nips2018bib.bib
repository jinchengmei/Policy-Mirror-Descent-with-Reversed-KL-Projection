@article{thrun1992efficient,
  title={Efficient exploration in reinforcement learning},
  author={Thrun, Sebastian B},
  journal={Technical report},
  year={1992}
}

@inproceedings{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2772--2782},
  year={2017}
}

@inproceedings{nachum2017improving,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle={ICLR},
  year={2017}
}

@article{williams1991function,
  title={Function optimization using connectionist reinforcement learning algorithms},
  author={Williams, Ronald J and Peng, Jing},
  journal={Connection Science},
  volume={3},
  number={3},
  pages={241--268},
  year={1991},
  publisher={Taylor \& Francis}
}

@article{williams1992simple,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Williams, Ronald J},
  journal={Machine Learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Kluwer Academic Publishers}
}

@inproceedings{norouzi2016reward,
  title={Reward augmented maximum likelihood for neural structured prediction},
  author={Norouzi, Mohammad and Bengio, Samy and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale and others},
  booktitle={Advances In Neural Information Processing Systems},
  pages={1723--1731},
  year={2016}
}

@book{owen2013monte,
  title={Monte Carlo theory, methods and examples},
  author={Owen, Art B.},
  year={2013}
}

@book{kevin2012machine, 
title = {Machine learning: a probabilistic perspective}, 
author = {Kevin, P Murphy}, 
year = {2012}, 
address = {Cambridge, MA} 
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@article{nemirovskii1983problem,
  title={Problem complexity and method efficiency in optimization},
  author={Nemirovskii, Arkadii and Yudin, David Borisovich and Dawson, Edgar Ronald},
  year={1983},
  publisher={Wiley}
}

@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007},
  organization={ACM}
}

@inproceedings{wierstra2008episodic,
  title={Episodic reinforcement learning by logistic reward-weighted regression},
  author={Wierstra, Daan and Schaul, Tom and Peters, Jan and Schmidhuber, Juergen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={407--416},
  year={2008},
  organization={Springer}
}

@inproceedings{peters2010relative,
  title={Relative Entropy Policy Search.},
  author={Peters, Jan and M{\"u}lling, Katharina and Altun, Yasemin},
  booktitle={AAAI},
  pages={1607--1612},
  year={2010},
  organization={Atlanta}
}

@inproceedings{montgomery2016guided,
  title={Guided policy search via approximate mirror descent},
  author={Montgomery, William H and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4008--4016},
  year={2016}
}

@inproceedings{nachum2017trust,
  title={Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={ICLR},
  year={2017}
}

@article{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@inproceedings{abdolmaleki2018maximum,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  booktitle={ICLR},
  year={2018}
}

@incollection{NIPS2017_6874,
title = {Cold-Start Reinforcement Learning with Softmax Policy Gradient},
author = {Ding, Nan and Soricut, Radu},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {2817--2826},
year = {2017},
url = {http://papers.nips.cc/paper/6874-cold-start-reinforcement-learning-with-softmax-policy-gradient.pdf}
}
