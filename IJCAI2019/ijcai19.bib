@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}

@article{lillicrap2015continuous,
	title={Continuous control with deep reinforcement learning},
	author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	journal={arXiv preprint arXiv:1509.02971},
	year={2015}
}

@book{sutton1998reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G and others},
	year={1998},
	publisher={MIT press}
}

@article{haarnoja2017reinforcement,
	title={Reinforcement learning with deep energy-based policies},
	author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
	journal={arXiv preprint arXiv:1702.08165},
	year={2017}
}

@article{schulman2017equivalence,
	title={Equivalence between policy gradients and soft q-learning},
	author={Schulman, John and Chen, Xi and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1704.06440},
	year={2017}
}

@article{fox2015taming,
	title={Taming the noise in reinforcement learning via soft updates},
	author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
	journal={arXiv preprint arXiv:1512.08562},
	year={2015}
}

@inproceedings{van2015learning,
	title={Learning of non-parametric control policies with high-dimensional state features},
	author={Van Hoof, Herke and Peters, Jan and Neumann, Gerhard},
	booktitle={Artificial Intelligence and Statistics},
	pages={995--1003},
	year={2015}
}

@inproceedings{peters2010relative,
	title={Relative Entropy Policy Search.},
	author={Peters, Jan and M{\"u}lling, Katharina and Altun, Yasemin},
	booktitle={AAAI},
	pages={1607--1612},
	year={2010},
	organization={Atlanta}
}

@article{tangkaratt2017guide,
	title={Guide Actor-Critic for Continuous Control},
	author={Tangkaratt, Voot and Abdolmaleki, Abbas and Sugiyama, Masashi},
	journal={arXiv preprint arXiv:1705.07606},
	year={2017}
}

@inproceedings{thomas2013projected,
	title={Projected natural actor-critic},
	author={Thomas, Philip S and Dabney, William C and Giguere, Stephen and Mahadevan, Sridhar},
	booktitle={Advances in neural information processing systems},
	pages={2337--2345},
	year={2013}
}

@article{mahadevan2012sparse,
	title={Sparse Q-learning with mirror descent},
	author={Mahadevan, Sridhar and Liu, Bo},
	journal={arXiv preprint arXiv:1210.4893},
	year={2012}
}

@inproceedings{liu2015finite,
	title={Finite-Sample Analysis of Proximal Gradient TD Algorithms.},
	author={Liu, Bo and Liu, Ji and Ghavamzadeh, Mohammad and Mahadevan, Sridhar and Petrik, Marek},
	booktitle={UAI},
	pages={504--513},
	year={2015},
	organization={Citeseer}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@article{williams1992simple,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Williams, Ronald J},
  journal={Machine Learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Kluwer Academic Publishers}
}

@article{williams1991function,
  title={Function optimization using connectionist reinforcement learning algorithms},
  author={Williams, Ronald J and Peng, Jing},
  journal={Connection Science},
  volume={3},
  number={3},
  pages={241--268},
  year={1991},
  publisher={Taylor \& Francis}
}

@article{thrun1992efficient,
  title={Efficient exploration in reinforcement learning},
  author={Thrun, Sebastian B},
  journal={Technical report},
  year={1992}
}

@inproceedings{nachum2017improving,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2772--2782},
  year={2017}
}

@article{nemirovskii1983problem,
  title={Problem complexity and method efficiency in optimization},
  author={Nemirovskii, Arkadii and Yudin, David Borisovich and Dawson, Edgar Ronald},
  year={1983},
  publisher={Wiley}
}

@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007},
  organization={ACM}
}

@inproceedings{wierstra2008episodic,
  title={Episodic reinforcement learning by logistic reward-weighted regression},
  author={Wierstra, Daan and Schaul, Tom and Peters, Jan and Schmidhuber, Juergen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={407--416},
  year={2008},
  organization={Springer}
}

@inproceedings{montgomery2016guided,
  title={Guided policy search via approximate mirror descent},
  author={Montgomery, William H and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4008--4016},
  year={2016}
}

@inproceedings{nachum2017trust,
  title={Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={ICLR},
  year={2017}
}

@article{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, Dave},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@inproceedings{abdolmaleki2018maximum,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  booktitle={ICLR},
  year={2018}
}

@book{kevin2012machine, 
title = {Machine learning: a probabilistic perspective}, 
author = {Kevin P Murphy}, 
year = {2012}, 
address = {Cambridge, MA} 
}

@inproceedings{norouzi2016reward,
  title={Reward augmented maximum likelihood for neural structured prediction},
  author={Norouzi, Mohammad and Bengio, Samy and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale and others},
  booktitle={Advances In Neural Information Processing Systems},
  pages={1723--1731},
  year={2016}
}

@inproceedings{ding2017cold,
  title={Cold-Start Reinforcement Learning with Softmax Policy Gradient},
  author={Ding, Nan and Soricut, Radu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2817--2826},
  year={2017}
}

@book{owen2013monte,
  title={Monte Carlo theory, methods and examples},
  author={Owen, Art B.},
  year={2013}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}